# -*- coding: utf-8 -*-
"""MajorProject_imputation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yzwCwPKRkvKKskzyHxxAUYA0u2ZaEHMi
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv("/content/diabetic_data.csv")
df.head(10)

df['label'] = df.readmitted.apply(lambda x: 1 if x == '<30' else 0)

ordinal_mappings =  {
    'age': {
        '[0-10)': 0, '[10-20)': 1, '[20-30)': 2, '[30-40)': 3, '[40-50)': 4,
        '[50-60)': 5, '[60-70)': 6, '[70-80)': 7, '[80-90)': 8, '[90-100)': 9
    }}

"""# MULTIPLE IMPUTATION

**MICE Model**

**MICE IMPLEMENTATION**
"""

from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer

import pandas as pd
import numpy as np
from sklearn.impute import IterativeImputer

df.replace('?', np.nan, inplace=True)

mice_df = df.copy()

# Separating numerical and categorical columns
numerical_cols = mice_df.select_dtypes(include=np.number).columns
categorical_cols = mice_df.select_dtypes(exclude=np.number).columns

# Impute missing values in numerical columns using IterativeImputer
imputer_numeric = IterativeImputer(max_iter=10, random_state=42)
mice_df[numerical_cols] = imputer_numeric.fit_transform(mice_df[numerical_cols])

# Fill missing values in categorical columns with mode
for col in categorical_cols:
    mice_df[col].fillna(mice_df[col].mode()[0], inplace=True)

# Create a new DataFrame preserving the original DataFrame
mice_df = df.copy()

"""**KNN IMPUTATION**"""

import pandas as pd
import numpy as np
from sklearn.impute import KNNImputer
from sklearn.preprocessing import LabelEncoder

# Make a copy of the original DataFrame
knn_df = df.copy()

# Separating numerical and categorical columns
numerical_cols = knn_df.select_dtypes(include=['number']).columns
categorical_cols = knn_df.select_dtypes(exclude=np.number).columns

# Initialize LabelEncoder for categorical columns
label_encoders = {}
for col in categorical_cols:
    label_encoders[col] = LabelEncoder()
    knn_df[col] = label_encoders[col].fit_transform(knn_df[col].astype(str))

# Initialize KNNImputer
knn_imputer = KNNImputer(n_neighbors=3)

# Perform KNN imputation on numerical columns
knn_df[numerical_cols] = knn_imputer.fit_transform(knn_df[numerical_cols])

# Inverse transform label encoded categorical variables
for col in categorical_cols:
    knn_df[col] = label_encoders[col].inverse_transform(knn_df[col])

print("\nImputed DataFrame (KNN):")
print(knn_df)

"""**MEAN/MODE**"""

import pandas as pd
from sklearn.impute import SimpleImputer

mean_df = df.copy()


# Impute missing values with mean for numerical columns
num_imputer = SimpleImputer(strategy='mean')
numerical_cols = mean_df.select_dtypes(include=['number']).columns
mean_df[numerical_cols] = num_imputer.fit_transform(mean_df[numerical_cols])

# Impute missing values with mode for categorical columns
cat_imputer = SimpleImputer(strategy='most_frequent')
categorical_cols = mean_df.select_dtypes(include=['object']).columns
mean_df[categorical_cols] = cat_imputer.fit_transform(df[categorical_cols])

print(mean_df)

"""# COMPARISON"""

import pandas as pd
import numpy as np
from sklearn.model_selection import cross_val_predict, train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import precision_score, recall_score, f1_score

#

# Create the target label
df['label'] = df.readmitted.apply(lambda x: 1 if x == '<30' else 0)

# Define target variable and features
target = 'label'
features = [col for col in df.columns if col != target]

# Function to preprocess data and return precision, recall, and F1-score
def evaluate_imputation_method(df, imputer):
    processed_df = df.copy()

    # Separate numerical and categorical columns
    numerical_cols = processed_df.select_dtypes(include=np.number).columns
    categorical_cols = processed_df.select_dtypes(exclude=np.number).columns

    # Apply label encoding to categorical columns
    label_encoders = {}
    for col in categorical_cols:
        label_encoders[col] = LabelEncoder()
        processed_df[col] = label_encoders[col].fit_transform(processed_df[col].astype(str))

    # Impute missing values
    processed_df[numerical_cols] = imputer.fit_transform(processed_df[numerical_cols])

    # Define X and y
    X = processed_df[features]
    y = processed_df[target]

    # Initialize and train model
    model = LogisticRegression()

    # Perform cross-validation predictions
    y_pred = cross_val_predict(model, X, y, cv=5)

    # Calculate precision, recall, and F1-score
    precision = precision_score(y, y_pred)
    recall = recall_score(y, y_pred)
    f1 = f1_score(y, y_pred)

    return precision, recall, f1

# Define imputers
imputers = {
    'Mean Imputation': SimpleImputer(strategy='mean'),
    'Mode Imputation': SimpleImputer(strategy='most_frequent'),
    'Iterative Imputation': IterativeImputer(max_iter=10, random_state=42),
    'KNN Imputation': KNNImputer(n_neighbors=3)
}

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(df.drop(target, axis=1), df[target], test_size=0.2, random_state=42)

# Evaluate each imputation method
results = {}
for imputer_name, imputer in imputers.items():
    precision, recall, f1 = evaluate_imputation_method(X_train, imputer)
    results[imputer_name] = {'Precision': precision, 'Recall': recall, 'F1-score': f1}

# Convert results to DataFrame
results_df = pd.DataFrame.from_dict(results, orient='index')

# Print results as a table
print("Imputation Method\tPrecision\tRecall\tF1-score")
print(results_df.to_string())

"""# OUTLIER DETECTION"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt


numerical_columns = ['time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient']

# Calculate Z-score for each selected column
z_scores = (mice_df[numerical_columns] - mice_df[numerical_columns].mean()) / mice_df[numerical_columns].std()

# Define a threshold for outliers (e.g., z-score greater than 3 or less than -3)
threshold = 3

# Find outliers using the Z-score method
outliers = (z_scores > threshold) | (z_scores < -threshold)

# Visualize outliers using boxplots
plt.figure(figsize=(12, 8))
for i, column in enumerate(numerical_columns):
    plt.subplot(3, 3, i + 1)
    sns.boxplot(data=mice_df[column], orient="h", whis=1.5)
    plt.title(f"Boxplot of {column}")
plt.tight_layout()
plt.show()

for column in numerical_columns:
    print(f"Outliers in column '{column}':")
    print(mice_df[outliers[column]][column])
    print("-----------------------")

"""# Correlation analysis using Pearson's formula"""

selected_columns = df.select_dtypes(include='number').columns[:50]

# Extracting data for selected columns
data = mice_df[selected_columns].to_numpy()

# Calculating Pearson's correlation coefficient manually for all column pairs
correlation_matrix = np.zeros((len(selected_columns), len(selected_columns)))

for i in range(len(selected_columns)):
    for j in range(len(selected_columns)):
        col1 = data[:, i]
        col2 = data[:, j]

        # Calculate mean of each column
        mean_col1 = np.mean(col1)
        mean_col2 = np.mean(col2)

        # Calculate Pearson's correlation coefficient
        numerator = np.sum((col1 - mean_col1) * (col2 - mean_col2))
        denominator = np.sqrt(np.sum((col1 - mean_col1)**2) * np.sum((col2 - mean_col2)**2))
        correlation = numerator / denominator if denominator != 0 else 0

        correlation_matrix[i, j] = correlation

# Create a DataFrame from the correlation matrix
correlation_df = pd.DataFrame(correlation_matrix, index=selected_columns, columns=selected_columns)

# Displaying the correlation matrix
print("Correlation Matrix (Pearson's Correlation Coefficients):")
print(correlation_df)

outlier_counts = outliers.sum()
print("Number of outliers in each column:")
print(outlier_counts)

correlation_df

import seaborn as sns
import matplotlib.pyplot as plt


# Plotting the heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(correlation_df, annot=False, cmap='coolwarm', fmt='.2f')
plt.title("Correlation Heatmap")
plt.show()

