# -*- coding: utf-8 -*-
"""OneHot_with_FeatureSelection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12XQTz1Orq9-61IehsuDGNMqSZjgiqhfX

## DATA ANALYSIS
"""

# Commented out IPython magic to ensure Python compatibility.
# Automatically reloading imported modules
# %load_ext autoreload
# %autoreload 2

import numpy as np
import pandas as pd
pd.set_option('display.max_columns', None)

import sys
sys.path.append('..')

import string
from functools import reduce

import missingno as msno

import seaborn as sns
import matplotlib.pyplot as plt

import time
from sklearn.model_selection import train_test_split

from scipy import sparse
from functools import reduce
import joblib
sys.modules['sklearn.externals.joblib'] = joblib
from sklearn.externals.joblib import Parallel, delayed
from sklearn.base import TransformerMixin
from sklearn.pipeline import FeatureUnion,  _fit_transform_one, _transform_one

from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from sklearn.metrics import accuracy_score, precision_score,\
    recall_score, roc_auc_score, f1_score, classification_report,\
    roc_curve, auc

from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix
import matplotlib.pyplot as plt
from sklearn.model_selection import learning_curve

from sklearn.pipeline import make_pipeline

from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer

import xgboost as xgb
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier, StackingClassifier
from sklearn.preprocessing import normalize

# Commented out IPython magic to ensure Python compatibility.
# Change design of plots
sns.set(style="whitegrid")

# Change sizes and resolution of plots
plt.rcParams['figure.figsize'] = (10, 6)
# %config InlineBackend.figure_format='retina'
plt.rcParams.update({'font.size': 15})

df = pd.read_csv('/content/diabetic_data.csv', na_values='?', low_memory=False)

df.shape

df.head()

"""Are there any duplicated rows?"""

df.duplicated().any()

"""Even there are no duplicates, the records represent individual encounters, so there can be more encounters for only one patient. Let's check the number of encounters and number of patients:"""

len(df.encounter_id.unique()), len(df.patient_nbr.unique())

df.readmitted.value_counts().plot(kind='pie', title='Distribution of predicted classes');

df.readmitted.value_counts()

"""**Even though the dataset contains 3 classes to be predicted, we transformed our task to binary classification - whether will patient be early readmitted or not (early readmitted is considered if readmission was in < 30 days).**"""

df['label'] = df.readmitted.apply(lambda x: 1 if x == '<30' else 0)

df.label.value_counts().plot(kind='pie', title='Distribution of predicted classes - binary');

df.label.value_counts()

"""As we can see, the data are highly imbalanced - just about 10% of the data are in minor positive class. Some methods like oversampling or undersampling should be done later."""

# Divide columns to 2 groups (too many columns for one plot)
column_groups = np.array_split(df.columns, 2)

for columns in column_groups:
    msno.bar(df[columns])
    plt.show()

for column in df.columns:
    missing_count = len(df[column][df[column].isna()])
    missing_percentage = round(missing_count / len(df) * 100, 2)
    if missing_count > 0:
        print(f'{column}: {missing_count} ({missing_percentage}%)')

len(df[df.diag_1.isna() & df.diag_2.isna() & df.diag_3.isna()])

"""There is only one that record, so it can be droppend in the preprocessing phase.

>Functions definitions
"""

def barplot_per_classes(df, attribute, groupby, title=None, ticks_rotation=0, topn=None, ax=None):

    uniq_values = df[attribute].value_counts().head(topn).index
    df = df[df[attribute].isin(uniq_values)]
    data = df.groupby(groupby)[attribute].value_counts(normalize=True).rename('percentage').mul(100).reset_index()
    sns.barplot(x=attribute, y='percentage', hue=groupby, data=data, ax=ax)  # Specify 'x' and 'y' arguments explicitly
    plt.xticks(rotation=ticks_rotation)
    plt.title(title)

def kdeplot_per_classes(df, attribute, groupby, title=None, ticks_rotation=0, ax=None):

    for x in df[groupby].unique():
        sns.kdeplot(df[df[groupby] == x][attribute], label=x, shade=True, shade_lowest=False, ax=ax)
    plt.title(title)
    plt.xticks(rotation=ticks_rotation)


def boxplot_per_classes(df, attribute, groupby, title=None, ticks_rotation=0, ax=None):

    sns.boxplot(x=groupby, y=attribute, data=df, ax=ax)
    plt.title(title)
    plt.xticks(rotation=ticks_rotation)

df.race.value_counts()

barplot_per_classes(df, 'race', 'label')

df.gender.value_counts()

barplot_per_classes(df, 'gender', 'label')

df.age.value_counts()

def convert_age(age):
    """
    Convert age from interval into middle value.

    :param age: age interval.
    :return: middle value of age interval.
    """
    age = age[1:-1]
    lower_boundary = int(age.split('-')[0])
    upper_boundary = int(age.split('-')[1])
    return (upper_boundary + lower_boundary) / 2

df['age_middle_value'] = df['age'].apply(lambda x: convert_age(x))

boxplot_per_classes(df, 'age_middle_value', 'label')

"""From the boxplot, we can see that there is only a minor difference at first sight."""

df.weight.value_counts()

""">diagnosis
Columns `diag_1`, `diag_2` and `diag_3` are codes for one of the type of diagnose. Here we need create mapping where diagnosis code is mapped to categorical value. We used rules from paper [1] to map more than 700 unique code values to 9 groups of diagnosis.

Let's check how many of unique values are there for each attribute (they can overlap of course):
"""

len(df.diag_1.unique()), len(df.diag_2.unique()), len(df.diag_3.unique())

def diagnosis_mapping():

    mapping = {}
    mapping['circulatory'] = list(range(390,460)) + [785]
    mapping['respiratory'] = list(range(460,520)) + [786]
    mapping['digestive'] = list(range(520,580)) + [787]
    mapping['diabetes'] = [250]
    mapping['injury'] = list(range(800,1000))
    mapping['musculoskeletal'] = list(range(710,740))
    mapping['genitourinary'] = list(range(580,630)) + [788]
    mapping['neoplasm'] = list(range(140,240))

    all_codes =  reduce(lambda x, y: x + mapping[y], mapping.keys(), [])
    mapping['other'] = [x for x in range(1,1000) if x not in all_codes]
    mapping['other'] = mapping['other'] + list(string.ascii_uppercase)

    for key in mapping.keys():
        mapping[key] = [str(x) for x in mapping[key]]
    return mapping

def map_code_to_diagnose(code, mapping):
    code = str(code)
    if not code:
        return None
    for diagnose in mapping.keys():
        if diagnose in ['diabetes', 'other']:
            if any([code.startswith(x) for x in mapping[diagnose]]):
                return diagnose
            else:
                continue
        if code in mapping[diagnose]:
            return diagnose

mapping = diagnosis_mapping()
df['diag_1_category'] = df.diag_1.apply(lambda x: map_code_to_diagnose(x, mapping))
df['diag_2_category'] = df.diag_2.apply(lambda x: map_code_to_diagnose(x, mapping))
df['diag_3_category'] = df.diag_3.apply(lambda x: map_code_to_diagnose(x, mapping))

""">diag_1
The primary diagnosis (coded as first three digits of ICD9); possibly 848 distinct values.

>Medicaments - 23 attributes

For the generic names: **metformin, repaglinide, nateglinide, chlorpropamide, glimepiride, acetohexamide, glipizide, glyburide, tolbutamide, pioglitazone, rosiglitazone, acarbose, miglitol, troglitazone, tolazamide, examide, sitagliptin, insulin, glyburide-metformin, glipizide-metformin, glimepiride-pioglitazone, metformin-rosiglitazone, and metformin-pioglitazone**, the feature indicates whether the drug was prescribed or there was a change in the dosage.

Values:
* `up` if the dosage was increased during the encounter,
* `down` if the dosage was decreased,
* `steady` if the dosage did not change,
* `no` if the drug was not prescribed.

All of those attributes will be analysed together:
"""

all_medicaments = [
    'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide','glimepiride',
    'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone',
    'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone', 'tolazamide', 'examide',
    'citoglipton', 'insulin','glyburide-metformin', 'glipizide-metformin',
    'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone'
]

""">change

*Change of medications* - Indicates if there was a change in diabetic medications (either dosage or generic name).

Values: `change` and `no change`.
"""

barplot_per_classes(df, 'change', 'label')

""">max_glu_serum

*Glucose serum test result* - Indicates the range of the result or if the test was not taken.

Values:
* `>200`,
* `>300`,
* `normal`,
* `none` if not measured.
"""

barplot_per_classes(df, 'max_glu_serum', 'label')

""">A1Cresult

Indicates the range of the result or if the test was not taken.

Values:
* `>8` if the result was greater than 8%,
* `>7` if the result was greater than 7% but less than 8%,
* `normal` if the result was less than 7%,
* `none` if not measured.
"""

barplot_per_classes(df, 'A1Cresult', 'label')

"""> diabetesMed

Indicates if there was any diabetic medication prescribed.
"""

barplot_per_classes(df, 'diabetesMed', 'label')

""">Feature engineering

In this section, we will create also some additional features/attributes from the data. Those attributes can aggregate the information and help in prediction.

>>number of visits

Sum of values in attributes: `number_emergency`, `number_outpatient`, `number_inpatient`
"""

df['visits_sum'] = df.apply(
    lambda x: x['number_emergency'] + x['number_outpatient'] + x['number_inpatient'], axis=1
)

kdeplot_per_classes(df, 'visits_sum', 'label')

boxplot_per_classes(df, 'visits_sum', 'label')

"""From the plots above, we can see that there is a difference between readmitted and not readmitted patients in summary of their visits in preceding year. This attribute can be used in prediction.

>>number of medicaments changes

Number of changes provided through all medicaments (23 features).
"""

col_name = 'number_medicaments_changes'
df[col_name] = 0

for medicament in all_medicaments:
    df[col_name] = df.apply(
        lambda x: x[col_name] + 1 if x[medicament] not in ['No', 'Steady'] else x[col_name], axis=1
    )

barplot_per_classes(df, 'number_medicaments_changes', 'label')

"""It's look like number of changes in medications (experimenting) can be interesting for prediction of patient's readmission. We will use this attribute in prediction to check its usefulness.

>> number of medicaments

Number of medicaments provided to patient (23 features).
"""

df['number_medicaments'] = df[all_medicaments].apply(
    lambda y: y.apply(lambda x: np.sum(0 if x == 'No' else 1)), axis=1
).apply(np.sum, axis=1)

barplot_per_classes(df, 'number_medicaments', 'label')

"""At first sight, number of medicaments prescribed to patient can be helpful in prediction of patient's readmission."""

columns =  [
    'num_medications', 'num_lab_procedures', 'num_procedures', 'time_in_hospital',
    'number_diagnoses', 'number_inpatient', 'number_outpatient', 'number_emergency',
    'visits_sum', 'age_middle_value', 'number_medicaments', 'number_medicaments_changes'
]

""">Correlation for numetrical attributes

Correlation heatmap showed those correlations:
* weak correlation between `num_medications` and `num_procedures`
* weak correlation between: `num_medications` and `time_in_hospital`, `num_procedures` and `time_in_hospital` - the longer patient stay in hospital, the more procedures/medications are provided to him
* weak correlation between `number_medicaments` and `number_medicaments_changes`
* moderate correlations between `visits_sum` and attributes `number_inpatient`, `number_outpatient` and `number_emergency`, but because the `visits_sum` is created as sum of the next three, it is not interesting information.
"""

fig, ax = plt.subplots(figsize=(10,10))
sns.heatmap(df[columns].corr(), annot=True, fmt=".2f", vmin=-1.0, vmax=1.0, square=True);

"""# TRANSFORMERS AND HELPER FUNCTIONS

Decorator
"""

def load_dataset():
    # Only needed changes in data types are listed
    data_types = {
        'admission_type_id': object,
        'discharge_disposition_id': object,
        'admission_source_id': object
    }

    return pd.read_csv(
        '/content/diabetic_data.csv',
        na_values='?',
        low_memory=False,
        dtype=data_types
    )

def transformer_time_calculation_decorator(transformer_name: str):

    def decorator(function):
        def wrapper(*args, **kwargs):
            start_time = time.time()

            result = function(*args, **kwargs)

            end_time = time.time()
            duration = round(end_time - start_time, 2)
            print(f'{transformer_name} transformation ended, '
                  f'took {duration} seconds.')

            return result
        return wrapper
    return decorator

"""Helper"""

def split_dataframe(x, y, test_size=0.2):
  return train_test_split(x, y, test_size=test_size, random_state=42)


def transform_label(y):
  return y.apply(lambda x: 1 if x == '<30' else 0)


def describe_dataset(X_train, X_test, y_train, y_test):
  print(f'Number of train data: {X_train.shape[0]}')
  print(f'Number of test data: {X_test.shape[0]}')
  print(f'Number of features: {X_train.columns.shape[0]}')
  categories = y_train['readmitted'].unique()
  print(f'Classes:')
  for c in categories:
    num_train = (y_train['readmitted'] == c).sum()
    num_test = (y_test['readmitted'] == c).sum()
    print(f'\t{c} :\n'
    f'\t    train: {num_train} samples, '
    f'{round(num_train / X_train.shape[0], 2) * 100}%\n'
    f'\t    test: {num_test} samples, '
    f'{round(num_test / X_test.shape[0], 2) * 100}%\n')

"""Transformers"""

class PandasFeatureUnion(FeatureUnion):
    def fit_transform(self, X, y=None, **fit_params):
        self._validate_transformers()
        result = Parallel(n_jobs=self.n_jobs)(
            delayed(_fit_transform_one)(
                transformer=trans,
                X=X,
                y=y,
                weight=weight,
                **fit_params)
            for name, trans, weight in self._iter())

        if not result:
            # All transformers are None
            return np.zeros((X.shape[0], 0))
        Xs, transformers = zip(*result)
        self._update_transformer_list(transformers)
        if any(sparse.issparse(f) for f in Xs):
            Xs = sparse.hstack(Xs).tocsr()
        else:
            Xs = self.merge_dataframes_by_column(Xs)
        return Xs

    def merge_dataframes_by_column(self, Xs):
        return pd.concat(Xs, axis="columns", copy=False)

    def transform(self, X):
        Xs = Parallel(n_jobs=self.n_jobs)(
            delayed(_transform_one)(
                transformer=trans,
                X=X,
                y=None,
                weight=weight)
            for name, trans, weight in self._iter())
        if not Xs:
            # All transformers are None
            return np.zeros((X.shape[0], 0))
        if any(sparse.issparse(f) for f in Xs):
            Xs = sparse.hstack(Xs).tocsr()
        else:
            Xs = self.merge_dataframes_by_column(Xs)
        return Xs


class ColumnsFilter(TransformerMixin):
    def __init__(self, columns):
        self.columns = columns

    def fit(self, df, y=None, **fit_params):
        return self

    @transformer_time_calculation_decorator('ColumnsFilter')
    def transform(self, df, **transform_params):
        df = df.drop(self.columns, axis=1, errors='ignore')
        return df


class RowsFilter(TransformerMixin):
    def __init__(self, indices):
        self.indices = indices

    def fit(self, df, y=None, **fit_params):
        return self

    @transformer_time_calculation_decorator('RowsFilter')
    def transform(self, df, **transform_params):
        df = df.drop(self.indices)
        return df


class RowsNanFilter(TransformerMixin):
    def __init__(self, threshold=0.3):
        self.threshold = threshold
        self.num_non_nan = None

    def fit(self, df, y=None, **fit_params):
        self.num_non_nan = round(df.shape[1] * (1 - self.threshold))
        return self

    @transformer_time_calculation_decorator('RowsNanFilter')
    def transform(self, df, **transform_params):
        df = df.dropna(thresh=self.num_non_nan)
        return df


class ColumnsNanFilter(TransformerMixin):
    def __init__(self, threshold=0.45):
        self.threshold = threshold
        self.columns = []

    def fit(self, df, y=None, **fit_params):
        for column in df.columns:
            threshold = df[column].isna().sum() / df[column].shape[0]
            if threshold > self.threshold:
                self.columns.append(column)
        return self

    @transformer_time_calculation_decorator('ColumnsNanFilter')
    def transform(self, df, **transform_params):
        df = df.drop(self.columns, axis=1)
        return df


class ColumnsValuesDiversityFilter(TransformerMixin):
    def __init__(self, threshold=1):
        self.columns = []
        self.threshold = threshold

    def fit(self, df, y=None, **fit_params):
        for column in df.columns:
            values = df[column].value_counts()
            threshold = values.max() / values.sum()
            if threshold >= self.threshold:
                self.columns.append(column)
        return self

    @transformer_time_calculation_decorator('ColumnsValuesDiversityFilter')
    def transform(self, df, **transform_params):
        df = df.drop(self.columns, axis=1)
        return df


class OneHotEncoder(TransformerMixin):
    def __init__(self, columns=None, exclude_columns=None):
        self.columns = columns
        self.exclude_columns = exclude_columns
        self.categories = {}

    def fit(self, df, y=None, **fit_params):
        self.columns = self.columns if self.columns is not None else df.columns
        if self.exclude_columns:
            self.columns = [x for x in self.columns
                            if x not in self.exclude_columns]
        for column in self.columns:
            self.categories[column] = set([
                f'{str(column)}_{str(val)}' for val in df[column].unique()
            ])
        return self

    @transformer_time_calculation_decorator('OneHotEncoder')
    def transform(self, df, **transform_params):
        df_copy = df.copy()
        for column in self.columns:
            df_copy = pd.concat(
                [df_copy, pd.get_dummies(df_copy[column], prefix=column)],
                axis=1
            )
            df_copy = self.add_missing_encoded_columns(df_copy, column)
        df_copy.drop(self.columns, axis=1, inplace=True)
        return df_copy

    def add_missing_encoded_columns(self, df, column):
        columns_to_add = self.categories[column] - set(df.columns)
        for column in columns_to_add:
            df[column] = 0
        return df


class ValueMapper(TransformerMixin):
    def __init__(self, mapping=None):
        if mapping is None:
            mapping = {}
        self.mapping = mapping

    def fit(self, df, y=None, **fit_params):
        return self

    @transformer_time_calculation_decorator('ValueMapper')
    def transform(self, df, **transform_params):
        df_copy = df.copy()
        for key in self.mapping.keys():
            column_mapping = self.mapping[key]
            df_copy[key] = df_copy[key].apply(
                lambda x: ValueMapper.get_value(x, column_mapping)
            )
        return df_copy

    @staticmethod
    def get_value(value, mapping):
        if pd.isna(value) or value not in mapping.keys():
            return None
        return mapping[value]


class MissingValuesImputer(TransformerMixin):
    def __init__(self, strategy, columns=None):
        self.columns = columns
        self.strategy = strategy
        self.mapping = {}

    def fit(self, df, y=None, **fit_params):
        self.columns = self.columns if self.columns is not None else df.columns

        for column in self.columns:
            if self.strategy == 'mean':
                self.mapping[column] = df[column].mean()
            elif self.strategy == 'median':
                self.mapping[column] = df[column].median()
            elif self.strategy == 'most_frequent':
                self.mapping[column] = df[column].mode()[0]
        return self

    @transformer_time_calculation_decorator('MissingValuesImputer')
    def transform(self, df, **transform_params):
        df_copy = df.copy()
        for column in self.columns:
            df_copy[column] = df_copy[column].fillna(self.mapping[column])
        return df_copy


class SmallCategoriesReducer(TransformerMixin):
    def __init__(
            self,
            columns=None,
            threshold=0.05,
            replace_value='other',
            exclude_columns=None
    ):
        self.columns = columns
        self.replace_value = replace_value
        self.threshold = threshold
        self.exclude_columns = exclude_columns
        self.mapping = {}

    def fit(self, df, y=None, **fit_params):
        if self.columns is None:
            self.columns = df.columns
        if self.exclude_columns is not None:
            self.columns = [
                x for x in self.columns if x not in self.exclude_columns
            ]

        for column in self.columns:
            values = df[column].value_counts(normalize=True)
            for name, value in values.iteritems():
                if value < self.threshold:
                    self.mapping[name] = self.replace_value
        return self

    @transformer_time_calculation_decorator('SmallCategoriesReducer')
    def transform(self, df, **transform_params):
        for column in self.columns:
            df[column] = df[column].apply(
                lambda x: SmallCategoriesReducer.get_value(x, self.mapping)
            )
        return df

    @staticmethod
    def get_value(value, mapping):
        if pd.isna(value):
            return None
        if value not in mapping.keys():
            return value
        return mapping[value]


class DiagnosesCodesMapper(TransformerMixin):

    def __init__(self, columns):
        self.columns = columns

    def fit(self, df, y=None, **fit_params):
        self.columns = [col for col in self.columns if col in df.columns]
        return self

    @staticmethod
    def diagnosis_mapping():
        mapping = dict()
        mapping['circulatory'] = list(range(390, 460)) + [785]
        mapping['respiratory'] = list(range(460, 520)) + [786]
        mapping['digestive'] = list(range(520, 580)) + [787]
        mapping['diabetes'] = [250]
        mapping['injury'] = list(range(800, 1000))
        mapping['musculoskeletal'] = list(range(710, 740))
        mapping['genitourinary'] = list(range(580, 630)) + [788]
        mapping['neoplasm'] = list(range(140, 240))

        all_codes = reduce(lambda x, y: x + mapping[y], mapping.keys(), [])
        mapping['other'] = [x for x in range(1, 1000) if x not in all_codes]
        mapping['other'] = mapping['other'] + list(string.ascii_uppercase)

        for key in mapping.keys():
            mapping[key] = [str(x) for x in mapping[key]]
        return mapping

    @staticmethod
    def map_code_to_diagnose(code, mapping):
        code = str(code)
        if not code:
            return None
        for diagnose in mapping.keys():
            if diagnose in ['diabetes', 'other']:
                if any([code.startswith(x) for x in mapping[diagnose]]):
                    return diagnose
                else:
                    continue
            if code in mapping[diagnose]:
                return diagnose

    @transformer_time_calculation_decorator('DiagnosesCodesMapper')
    def transform(self, df, **transform_params):
        df_copy = df.copy()

        mapping = DiagnosesCodesMapper.diagnosis_mapping()

        for column in self.columns:
            df_copy[f'{column}_category'] = df_copy[column].apply(
                lambda x: DiagnosesCodesMapper.map_code_to_diagnose(x, mapping)
            )
        df_copy = df_copy.drop(self.columns, axis=1)
        return df_copy


class NumberVisitsCreator(TransformerMixin):
    def __init__(self, columns):
        self.columns = columns

    def fit(self, df, y=None, **fit_params):
        return self

    @transformer_time_calculation_decorator('NumberVisitsCreator')
    def transform(self, df, **transform_params):
        df_copy = df.copy()

        df_copy['visits_sum'] = df_copy.loc[:, self.columns].sum(axis=1)

        return df_copy


class NumberMedicamentsChangesCreator(TransformerMixin):
    def __init__(self, columns):
        self.columns = columns

    def fit(self, df, y=None, **fit_params):
        self.columns = [col for col in self.columns if col in df.columns]
        return self

    @staticmethod
    def counter(counter_value, medicament):
        if medicament not in ['No', 'Steady']:
            return counter_value + 1
        return counter_value

    @transformer_time_calculation_decorator('NumberMedicamentsChangesCreator')
    def transform(self, df, **transform_params):
        df_copy = df.copy()
        col_name = 'number_medicaments_changes'

        df_copy[col_name] = 0

        for medicament in self.columns:
            df_copy[col_name] = df_copy.apply(
                lambda x: NumberMedicamentsChangesCreator.counter(
                    x[col_name], x[medicament]
                ),
                axis=1
            )

        return df_copy


class NumberMedicamentsCreator(TransformerMixin):
    def __init__(self, columns):
        self.columns = columns

    def fit(self, df, y=None, **fit_params):
        self.columns = [col for col in self.columns if col in df.columns]
        return self

    @transformer_time_calculation_decorator('NumberMedicamentsCreator')
    def transform(self, df, **transform_params):
        df_copy = df.copy()
        col_name = 'number_medicaments'

        df_copy[col_name] = df_copy[self.columns].apply(
            lambda y: y.apply(lambda x: np.sum(0 if x == 'No' else 1)), axis=1
        ).apply(np.sum, axis=1)

        return df_copy

"""Evaluation classes"""

def undersample(x, y):

    rus = RandomUnderSampler(random_state=3)
    return rus.fit_resample(x, y)


def oversample(x, y):

    smote = SMOTE(random_state=42)
    return smote.fit_resample(x, y)


def compare_models(models, names, x, y):

    max_len = np.max([len(x) for x in names])
    print("      ".ljust(max_len) + "     Accuracy   F1 (micro)  F1 (macro)"
                                    "  Precision   Recall    AUC ROC")
    for i, model in enumerate(models):
        y_pred = model.predict(x)
        y_pred_prob = model.predict_proba(x)[:, 1]
        print(f"{names[i]}" + "".ljust(max_len-len(names[i])) + "   "
              f"|   {accuracy_score(y, y_pred):.2f}   "
              f"|   {f1_score(y, y_pred, average='micro'):.2f}    "
              f"|   {f1_score(y, y_pred, average='macro'):.2f}    "
              f"|   {precision_score(y, y_pred):.2f}    "
              f"|   {recall_score(y, y_pred):.2f}   "
              f"|   {roc_auc_score(y, y_pred_prob):.2f}   |")




def evaluate_model(model, x, y):
    y_pred = model.predict(x)
    y_pred_prob = model.predict_proba(x)[:, 1]
    cm = confusion_matrix(y, y_pred)

    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12, 4), constrained_layout=True)

    # Normalize confusion matrix manually
    cm_normalized = normalize(cm, axis=1, norm='l1')

    cm_display = ConfusionMatrixDisplay(confusion_matrix=cm_normalized, display_labels=model.classes_)
    cm_display.plot(cmap=plt.cm.Blues, ax=axs[0], xticks_rotation='horizontal', values_format='.2f')

    fpr, tpr, _ = roc_curve(y, y_pred_prob)
    axs[1].plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc_score(y, y_pred_prob):.2f})')
    axs[1].plot([0, 1], [0, 1], 'k--')
    axs[1].set_xlabel('False Positive Rate')
    axs[1].set_ylabel('True Positive Rate')
    axs[1].set_title('ROC Curve')
    axs[1].legend(loc='lower right')

    print(classification_report(y, y_pred))
    print(f'ROC AUC score: {round(roc_auc_score(y, y_pred_prob), 3)}')

    plt.show()



def roc_auc(y_pred_prob, y_true, plot=True, label="curve", ax=None):
    fpr, tpr, _ = roc_curve(y_true, y_pred_prob)
    auc_value = auc(fpr, tpr)

    if plot:
        if not ax:
            fig, ax = plt.subplots()
        ax.scatter(x=fpr, y=tpr, color='navy')
        ax.plot(
            fpr, tpr,
            c=tuple(np.random.rand(3, 1)[:, 0]),
            lw=2,
            label=f'{label} (AUC = {round(auc_value, 3)})'
        )
        ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        ax.set_xlim([0.0, 1.0])
        ax.set_ylim([0.0, 1.05])
        ax.set_xlabel('False Positive Rate')
        ax.set_ylabel('True Positive Rate')
        ax.set_title('ROC Curve')
        ax.legend(loc="lower right")

    return auc_value

'''
def plot_feature_importance(
    importance,
    feature_names,
    max_num=-1,
    reverse_order=False
):
    """
    Plot features sorted by importance.

    :param importance: importance of features.
    :param feature_names: names of features.
    :param max_num: maximal number of features to show.
    :param reverse_order: whether importances are in reverse order.
    :return: feature names sorted by importance.
    """
    indexes = np.argsort(importance)
    names = []
    feature_importance = []

    if reverse_order:
        indexes = list(reversed(indexes))

    for i in indexes:
        names.append(feature_names[i])
        feature_importance.append(importance[i])

    plt.figure(figsize=(10, len(feature_names[:max_num]) // 2))
    plt.barh(names[-max_num::], feature_importance[-max_num::])
    plt.yticklabels = names

    return names[::-1]

'''
def plot_learning_curve(
        estimator, title, X, y, cv=None, train_sizes=np.linspace(.1, 1.0, 10)
):
    plt.figure()
    plt.title(title)
    plt.ylim(0.45, 1.01)
    plt.xlabel('Number of samples', labelpad=20)
    plt.ylabel('Score', labelpad=20)
    train_sizes, train_scores, test_scores = learning_curve(
        estimator, X, y, cv=cv, n_jobs=-1, train_sizes=train_sizes)
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)
    plt.grid()

    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,
                     train_scores_mean + train_scores_std, alpha=0.1,
                     color="r")
    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,
                     test_scores_mean + test_scores_std, alpha=0.1, color="g")
    plt.plot(train_sizes, train_scores_mean, 'o-', color="r",
             label='Train score')
    plt.plot(train_sizes, test_scores_mean, 'o-', color="g",
             label='Cross-validation score')

    plt.legend(loc='best')
    return plt

"""# DATA PREPROCESSING

>Initial Preprocessing
"""

df = load_dataset()

indices_to_drop = set()
indices_to_drop.update(list(df[df.diag_1.isna() & df.diag_2.isna() & df.diag_3.isna()].index))
indices_to_drop.update(list(df[~df.gender.isin(['Male', 'Female'])].index))
initial_preprocessing_pipeline = make_pipeline(
    RowsNanFilter(),
    RowsFilter(indices_to_drop),
)
df = initial_preprocessing_pipeline.fit_transform(df)

""">MICE Imputation"""

numerical_cols = df.select_dtypes(include=np.number).columns
categorical_cols = df.select_dtypes(exclude=np.number).columns

imputer_numeric = IterativeImputer(max_iter=10, random_state=42)
df[numerical_cols] = imputer_numeric.fit_transform(df[numerical_cols])

for col in categorical_cols:
    df[col].fillna(df[col].mode()[0], inplace=True)
print("Imputed DataFrame (MICE-like) with '?' handled as missing values:")
print(df)





df.shape[1]

X = df.drop('readmitted', axis=1)
y = transform_label(df['readmitted'])
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train.head()



""">Drop redundant columns"""

columns_to_drop = ['encounter_id', 'patient_nbr', 'payer_code']

""">Small categories reducing"""

columns_to_reduce = ['discharge_disposition_id', 'admission_source_id']

ordinal_mappings =  {
    'age': {
        '[0-10)': 0, '[10-20)': 1, '[20-30)': 2, '[30-40)': 3, '[40-50)': 4,
        '[50-60)': 5, '[60-70)': 6, '[70-80)': 7, '[80-90)': 8, '[90-100)': 9
    }}

"""> Feature Engineering"""

visits_cols = ['number_emergency', 'number_outpatient', 'number_inpatient']
medicaments_cols = [
    'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide','glimepiride',
    'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone',
    'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone', 'tolazamide', 'examide',
    'citoglipton', 'insulin','glyburide-metformin', 'glipizide-metformin',
    'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone'
]
diagnoses_cols = ['diag_1', 'diag_2', 'diag_3']

categorical_features = X_train.select_dtypes(include=object).columns.tolist()
numerical_features = X_train.select_dtypes(exclude=object).columns.tolist()
except_medicaments_cols = list(set(X_train.columns) - set(medicaments_cols))

""">Pipeline"""

preprocessing_pipeline = make_pipeline(
    ColumnsFilter(columns_to_drop),
    ColumnsNanFilter(),
    PandasFeatureUnion([
        ('numerical_features', make_pipeline(
            ColumnsFilter(categorical_features),
            MissingValuesImputer(strategy='median'),
           # NumberVisitsCreator(visits_cols),
        )),
        ('categorical_features', make_pipeline(
            ColumnsFilter(numerical_features),
            #DiagnosesCodesMapper(diagnoses_cols),
            MissingValuesImputer(strategy='most_frequent'),
            #SmallCategoriesReducer(exclude_columns=['age']),
            ColumnsValuesDiversityFilter(0.9),
            #ValueMapper(ordinal_mappings),
            #OneHotEncoder(exclude_columns=['age'])
            OneHotEncoder()
        )),
        #('medicaments_features', make_pipeline(
         #   ColumnsFilter(except_medicaments_cols),
          #  NumberMedicamentsChangesCreator(medicaments_cols),
           # NumberMedicamentsCreator(medicaments_cols),
            #ColumnsFilter(medicaments_cols)

    ])
)

X_train_prep = preprocessing_pipeline.fit_transform(X_train)
X_test_prep = preprocessing_pipeline.transform(X_test)

X_train_prep.shape[1], X_test_prep.shape[1]

X_train = X_train_prep
X_test = X_test_prep

"""# BORUTA FEATURE SELECTION"""

from boruta import BorutaPy
from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(n_estimators=100, n_jobs=-1, class_weight='balanced', max_depth=5)

# Initialize Boruta feature selector
boruta_feature_selector = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=42)

# Fit Boruta feature selector on your preprocessed training data
boruta_feature_selector.fit(X_train.values, y_train.values)

# Check selected features
selected_features = X_train.columns[boruta_feature_selector.support_].tolist()
print("Selected features:", selected_features)
print("Ranking of features:", boruta_feature_selector.ranking_)


X_train_selected = boruta_feature_selector.transform(X_train.values)
X_test_selected = boruta_feature_selector.transform(X_test.values)

X_test = X_test.drop(columns=['medical_specialty_Dermatology', 'medical_specialty_Perinatology'])

feature_importance = boruta_feature_selector.ranking_

plt.figure(figsize=(15, 15))
plt.barh(range(len(feature_importance)), feature_importance, align='center')
plt.yticks(range(len(X_train.columns)), X_train.columns)
plt.xlabel('Boruta Feature Importance')
plt.ylabel('Feature')
plt.title('Boruta Feature Importance')
plt.show()

X_train = boruta_feature_selector.transform(X_train.values)

X_test = boruta_feature_selector.transform(X_test.values)

"""# MODEL SELECTION

>Undersampling by Random
"""

X_train_undersampled, y_train_undersampled = undersample(X_train, y_train)
len(X_train_undersampled), len(y_train_undersampled)

""">Oversampling bY SMOTE"""

X_train_oversampled, y_train_oversampled = oversample(X_train, y_train)
len(X_train_oversampled), len(y_train_oversampled)

"""1. Random Forest

>>Original dataset
"""

rf = RandomForestClassifier(max_depth=10, random_state=42, class_weight="balanced")
rf.fit(X_train, y_train)
evaluate_model(rf, X_test, y_test)

""">>Undersampled data

"""

rf_u = RandomForestClassifier(max_depth=10, random_state=42)
rf_u.fit(X_train_undersampled, y_train_undersampled)
evaluate_model(rf_u, X_test, y_test)

rf_o = RandomForestClassifier(max_depth=10, random_state=42, class_weight={0:1,1:4})
rf_o.fit(X_train_oversampled, y_train_oversampled)
evaluate_model(rf_o, X_test, y_test)

compare_models([rf, rf_u, rf_o],
               ['RF', 'RF undersampled', 'RF oversampled'],
               X_test, y_test)

"""XG Boost"""

xg = xgb.XGBClassifier(
    random_state=42, learning_rate=0.001,
    max_depth=6, scale_pos_weight=9
)
xg.fit(X_train,y_train)
evaluate_model(xg, X_test, y_test)

xg_u = xgb.XGBClassifier(random_state=42, learning_rate=0.01, max_depth=6)
xg_u.fit(X_train_undersampled, y_train_undersampled)
evaluate_model(xg_u, X_test, y_test)

xg_o = xgb.XGBClassifier(random_state=42, learning_rate=0.001, scale_pos_weight=4)
xg_o.fit(X_train_oversampled, y_train_oversampled)
evaluate_model(xg_o, X_test, y_test)

compare_models([xg, xg_u, xg_o],
               ['XGBoost', 'XGBoost undersampled', 'XGBoost oversampled'],
               X_test, y_test)

"""MLP"""

mlp = MLPClassifier(
    hidden_layer_sizes=(128,64), max_iter=30,
    activation='relu', solver='adam',
    random_state=42
)
mlp.fit(X_train, y_train)
evaluate_model(mlp, X_test, y_test)

mlp_u = MLPClassifier(
    hidden_layer_sizes=(128,64), max_iter=20,
    activation='relu', solver='adam',
    random_state=42
)
mlp_u.fit(X_train_undersampled, y_train_undersampled)
evaluate_model(mlp_u, X_test, y_test)

mlp_o = MLPClassifier(
    hidden_layer_sizes=(128,64), max_iter=20,
    activation='relu', solver='adam',
    random_state=42
)
mlp_o.fit(X_train_oversampled, y_train_oversampled)
evaluate_model(mlp_o, X_test, y_test)

compare_models([mlp, mlp_u, mlp_o],
               ['MLP', 'MLP undersampled', 'MLP oversampled'],
               X_test, y_test)

compare_models(
    [rf, rf_u, rf_o, xg, xg_u, xg_o, mlp, mlp_u, mlp_o,],
    ['RF', 'RF undersampled', 'RF oversampled',
     'XGBoost', 'XGBoost undersampled', 'XGBoost oversampled',
     'MLP', 'MLP undersampled', 'MLP oversampled'],
   X_test, y_test)

"""# CNN
>Original
"""

from sklearn.preprocessing import StandardScaler
from keras.models import Sequential
from keras.layers import Dense, Conv1D, Flatten

X_train_array = X_train.values

X_train_reshaped = X_train_array.reshape(-1, X_train_array.shape[1], 1)
X_test_reshaped = X_test.values.reshape(-1, X_test.values.shape[1], 1)

cnn = Sequential()
cnn.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train_reshaped.shape[1], 1)))
cnn.add(Flatten())
cnn.add(Dense(64, activation='relu'))
cnn.add(Dense(1, activation='sigmoid'))

cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

cnn.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))

def evaluate_model_cnn(model, x, y):
    y_pred_prob = model.predict(x)
    y_pred = (y_pred_prob > 0.5).astype(int)
    cm = confusion_matrix(y, y_pred)

    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12, 4), constrained_layout=True)

    # Normalize confusion matrix manually
    cm_normalized = normalize(cm, axis=1, norm='l1')

    # Define the display labels manually
    display_labels = ['0', '1']
    cm_display = ConfusionMatrixDisplay(confusion_matrix=cm_normalized, display_labels=display_labels)
    cm_display.plot(cmap=plt.cm.Blues, ax=axs[0], xticks_rotation='horizontal', values_format='.2f')

    fpr, tpr, _ = roc_curve(y, y_pred_prob)
    axs[1].plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc_score(y, y_pred_prob):.2f})')
    axs[1].plot([0, 1], [0, 1], 'k--')
    axs[1].set_xlabel('False Positive Rate')
    axs[1].set_ylabel('True Positive Rate')
    axs[1].set_title('ROC Curve')
    axs[1].legend(loc='lower right')

    print(classification_report(y, y_pred))
    print(f'ROC AUC score: {round(roc_auc_score(y, y_pred_prob), 3)}')

    plt.show()

evaluate_model_cnn(cnn, X_test_reshaped, y_test)

# Predict probabilities for the test data
y_pred_prob = cnn.predict(X_test_reshaped)

# Convert probabilities to class labels based on a threshold (e.g., 0.5)
y_pred = (y_pred_prob > 0.5).astype(int)

accuracy = accuracy_score(y_test, y_pred)
f1_micro = f1_score(y_test, y_pred, average='micro')
f1_macro = f1_score(y_test, y_pred, average='macro')
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
auc_roc = roc_auc_score(y_test, y_pred_prob)

scores = {
    "Score": ["Accuracy", "F1 (micro)", "F1 (macro)", "Precision", "Recall", "AUC ROC"],
    "Value": [accuracy, f1_micro, f1_macro, precision, recall, auc_roc]
}


print("Score".ljust(15), end="")
for score in scores["Score"]:
    print(score.rjust(12), end="")
print()

print("-" * 90)

print("Value".ljust(15), end="")
for value in scores["Value"]:
    print(f"{value:.2f}".rjust(12), end="")
print()

"""#NN

"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

from sklearn.preprocessing import MinMaxScaler

# Assuming X_train is your original feature data
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
def create_nn_model(input_shape):
    model = Sequential([
        Dense(64, activation='relu', input_shape=(input_shape,)),  # Correct input_shape format
        Dropout(0.2),
        Dense(32, activation='relu'),
        Dropout(0.2),
        Dense(1, activation='sigmoid')
    ])
    return model

input_shape = X_train_scaled.shape[1]  # Number of features
nn_model = create_nn_model(input_shape)
nn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
nn_model.summary()

# Define the neural network model
nn_model = create_nn_model(input_shape)

nn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

nn_model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, verbose=1)


nn_o = nn_model.fit(X_train_oversampled, y_train_oversampled, epochs=10, batch_size=32, verbose=1)

nn_u = nn_model.fit(X_train_undersampled, y_train_undersampled, epochs=10, batch_size=32, verbose=1)

# Make predictions for each model
original_predictions = nn_model.predict(X_test)
oversampled_predictions = nn_o.model.predict(X_test)  # Accessing model from the History object
undersampled_predictions = nn_u.model.predict(X_test)  # Accessing model from the History object

# Round predictions to convert probabilities to binary predictions
original_predictions = np.round(original_predictions)
oversampled_predictions = np.round(oversampled_predictions)
undersampled_predictions = np.round(undersampled_predictions)

# Calculate evaluation metrics
original_accuracy = accuracy_score(y_test, original_predictions)
original_f1_micro = f1_score(y_test, original_predictions, average='micro')
original_f1_macro = f1_score(y_test, original_predictions, average='macro')
original_precision = precision_score(y_test, original_predictions)
original_recall = recall_score(y_test, original_predictions)
original_auc_roc = roc_auc_score(y_test, original_predictions)

oversampled_accuracy = accuracy_score(y_test, oversampled_predictions)
oversampled_f1_micro = f1_score(y_test, oversampled_predictions, average='micro')
oversampled_f1_macro = f1_score(y_test, oversampled_predictions, average='macro')
oversampled_precision = precision_score(y_test, oversampled_predictions)
oversampled_recall = recall_score(y_test, oversampled_predictions)
oversampled_auc_roc = roc_auc_score(y_test, oversampled_predictions)

undersampled_accuracy = accuracy_score(y_test, undersampled_predictions)
undersampled_f1_micro = f1_score(y_test, undersampled_predictions, average='micro')
undersampled_f1_macro = f1_score(y_test, undersampled_predictions, average='macro')
undersampled_precision = precision_score(y_test, undersampled_predictions)
undersampled_recall = recall_score(y_test, undersampled_predictions)
undersampled_auc_roc = roc_auc_score(y_test, undersampled_predictions)

original_predictions

oversampled_predictions

undersampled_predictions

from tabulate import tabulate

# Define evaluation results
evaluation_results = [
    ["Metric", "Original Model", "Oversampled Model", "Undersampled Model"],
    ["Accuracy", original_accuracy, oversampled_accuracy, undersampled_accuracy],
    ["F1 (micro)", original_f1_micro, oversampled_f1_micro, undersampled_f1_micro],
    ["F1 (macro)", original_f1_macro, oversampled_f1_macro, undersampled_f1_macro],
    ["Precision", original_precision, oversampled_precision, undersampled_precision],
    ["Recall", original_recall, oversampled_recall, undersampled_recall],
    ["AUC ROC", original_auc_roc, oversampled_auc_roc, undersampled_auc_roc]
]

# Print the table
print(tabulate(evaluation_results, headers="firstrow", tablefmt="fancy_grid"))

from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score
import matplotlib.pyplot as plt

# Predictions on original dataset
original_predictions = nn_model.predict(X_train_scaled)
original_predictions = (original_predictions > 0.5).astype(int)

# Predictions on oversampled dataset
oversampled_predictions = nn_model.predict(X_train_oversampled)
oversampled_predictions = (oversampled_predictions > 0.5).astype(int)

# Predictions on undersampled dataset
undersampled_predictions = nn_model.predict(X_train_undersampled)
undersampled_predictions = (undersampled_predictions > 0.5).astype(int)

# Classification report
print("Classification Report (Original Dataset):")
print(classification_report(y_train, original_predictions))

print("Classification Report (Oversampled Dataset):")
print(classification_report(y_train_oversampled, oversampled_predictions))

print("Classification Report (Undersampled Dataset):")
print(classification_report(y_train_undersampled, undersampled_predictions))

# Confusion matrix
def plot_confusion_matrix(cm, labels):
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title('Confusion Matrix')
    plt.colorbar()
    tick_marks = [i for i in range(len(labels))]
    plt.xticks(tick_marks, labels, rotation=45)
    plt.yticks(tick_marks, labels)
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.show()

cm_original = confusion_matrix(y_train, original_predictions)
cm_oversampled = confusion_matrix(y_train_oversampled, oversampled_predictions)
cm_undersampled = confusion_matrix(y_train_undersampled, undersampled_predictions)

print("Confusion Matrix (Original Dataset):")
print(cm_original)
plot_confusion_matrix(cm_original, ['Negative', 'Positive'])

print("Confusion Matrix (Oversampled Dataset):")
print(cm_oversampled)
plot_confusion_matrix(cm_oversampled, ['Negative', 'Positive'])

print("Confusion Matrix (Undersampled Dataset):")
print(cm_undersampled)
plot_confusion_matrix(cm_undersampled, ['Negative', 'Positive'])

# ROC curve
fpr_original, tpr_original, thresholds_original = roc_curve(y_train, original_predictions)
fpr_oversampled, tpr_oversampled, thresholds_oversampled = roc_curve(y_train_oversampled, oversampled_predictions)
fpr_undersampled, tpr_undersampled, thresholds_undersampled = roc_curve(y_train_undersampled, undersampled_predictions)

plt.plot(fpr_original, tpr_original, label='Original Dataset')
plt.plot(fpr_oversampled, tpr_oversampled, label='Oversampled Dataset')
plt.plot(fpr_undersampled, tpr_undersampled, label='Undersampled Dataset')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()

# ROC AUC score
roc_auc_original = roc_auc_score(y_train, original_predictions)
roc_auc_oversampled = roc_auc_score(y_train_oversampled, oversampled_predictions)
roc_auc_undersampled = roc_auc_score(y_train_undersampled, undersampled_predictions)

print("ROC AUC Score (Original Dataset):", roc_auc_original)
print("ROC AUC Score (Oversampled Dataset):", roc_auc_oversampled)
print("ROC AUC Score (Undersampled Dataset):", roc_auc_undersampled)



"""# LSTM
>1. ORIGINAL
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from keras.models import Sequential
from keras.layers import LSTM, Dense
from keras.optimizers import Adam

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Reshape the input data for LSTM
X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))
X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))

# Define the LSTM model
model = Sequential()
model.add(LSTM(units=50, activation='relu', input_shape=(1, X_train_scaled.shape[1])))
model.add(Dense(units=1, activation='sigmoid'))  # Assuming binary classification (readmitted or not)

# Compile the model
optimizer = Adam(lr=0.001)
model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, verbose=1)

# Evaluate the model
loss, accuracy = model.evaluate(X_test_reshaped, y_test)
print("Test Loss:", loss)
print("Test Accuracy:", accuracy)

evaluate_model_cnn(model, X_test_reshaped, y_test)

# Predict probabilities for the test data
y_pred_prob = model.predict(X_test_reshaped)

# Convert probabilities to class labels based on a threshold (e.g., 0.5)
y_pred = (y_pred_prob > 0.5).astype(int)

accuracy = accuracy_score(y_test, y_pred)
f1_micro = f1_score(y_test, y_pred, average='micro')
f1_macro = f1_score(y_test, y_pred, average='macro')
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
auc_roc = roc_auc_score(y_test, y_pred_prob)

scores = {
    "Score": ["Accuracy", "F1 (micro)", "F1 (macro)", "Precision", "Recall", "AUC ROC"],
    "Value": [accuracy, f1_micro, f1_macro, precision, recall, auc_roc]
}


print("Score".ljust(15), end="")
for score in scores["Score"]:
    print(score.rjust(12), end="")
print()

print("-" * 90)

print("Value".ljust(15), end="")
for value in scores["Value"]:
    print(f"{value:.2f}".rjust(12), end="")
print()

"""#LSTM
> Undersampled and Oversampled
"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense

def create_lstm_conv_model(input_shape, filters=32, kernel_size=3, pool_size=2, lstm_units=100):
    model = Sequential()
    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', input_shape=input_shape))
    model.add(MaxPooling1D(pool_size=pool_size))
    model.add(LSTM(units=lstm_units))
    model.add(Dense(1, activation='sigmoid'))
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

input_shape = (X_train_scaled.shape[1], 1)

X_test_scaled_array = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)

X_train_oversampled_array = X_train_oversampled.to_numpy().reshape(X_train_oversampled.shape[0], X_train_oversampled.shape[1], 1)
X_train_undersampled_array = X_train_undersampled.to_numpy().reshape(X_train_undersampled.shape[0], X_train_undersampled.shape[1], 1)
y_train_oversampled_array = y_train_oversampled.to_numpy().reshape(-1, 1)
y_train_undersampled_array = y_train_undersampled.to_numpy().reshape(-1, 1)

# Create separate model instances for oversampled and undersampled data
lstm_o = create_lstm_conv_model(input_shape)
lstm_u = create_lstm_conv_model(input_shape)

# Train the models
lstm_o.fit(X_train_oversampled_array, y_train_oversampled_array, epochs=10, batch_size=32, verbose=1)
accuracy_oversampled = lstm_o.evaluate(X_test_scaled_array, y_test)[1]
print("Accuracy on oversampled test set:", accuracy_oversampled)

lstm_u.fit(X_train_undersampled_array, y_train_undersampled_array, epochs=10, batch_size=32, verbose=1)
accuracy_undersampled = lstm_u.evaluate(X_test_scaled_array, y_test)[1]
print("Accuracy on undersampled test set:", accuracy_undersampled)

from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score
import numpy as np

# Define function to compute evaluation metrics
def compute_metrics(model, X_test, y_test):
    y_pred = model.predict(X_test)
    y_pred_binary = (y_pred > 0.5).astype(int)

    accuracy = accuracy_score(y_test, y_pred_binary)
    f1_micro = f1_score(y_test, y_pred_binary, average='micro')
    f1_macro = f1_score(y_test, y_pred_binary, average='macro')
    precision = precision_score(y_test, y_pred_binary)
    recall = recall_score(y_test, y_pred_binary)
    auc_roc = roc_auc_score(y_test, y_pred)

    return accuracy, f1_micro, f1_macro, precision, recall, auc_roc

# Reshape input data to match model input shape
X_test_reshaped = X_test.values.reshape(X_test.shape[0], X_test.shape[1], 1)  # Assuming X_test is your DataFrame

# Compute metrics for oversampled and undersampled models
accuracy_oversampled, f1_micro_oversampled, f1_macro_oversampled, precision_oversampled, recall_oversampled, auc_roc_oversampled = compute_metrics(lstm_o, X_test_reshaped, y_test)
accuracy_undersampled, f1_micro_undersampled, f1_macro_undersampled, precision_undersampled, recall_undersampled, auc_roc_undersampled = compute_metrics(lstm_u, X_test_reshaped, y_test)

# Display metrics in tabular format
from tabulate import tabulate

metrics_table = [
    ["Metric", "Oversampled", "Undersampled"],
    ["Accuracy", accuracy_oversampled, accuracy_undersampled],
    ["F1 (micro)", f1_micro_oversampled, f1_micro_undersampled],
    ["F1 (macro)", f1_macro_oversampled, f1_macro_undersampled],
    ["Precision", precision_oversampled, precision_undersampled],
    ["Recall", recall_oversampled, recall_undersampled],
    ["AUC ROC", auc_roc_oversampled, auc_roc_undersampled]
]

print(tabulate(metrics_table, headers="firstrow", tablefmt="fancy_grid"))

